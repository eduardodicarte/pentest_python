# encoding: utf-8
import sys
import urllib

urls_path = []
urls_file = []


def initialize():
    url = sys.argv[1:]

    if not len(url):
        print "Uma url e necessária para iniciar o mapeamento"
        return

    init_process(url)


def init_process(url):
    #recupera a url no formato correto esperado pelo urllib
    site = get_site(url)

    #após recuperado o site, recupera todos os links encontrados na página adicionando ao array urls
    page = read_site(site)

    #recupera as urls da página e adiciona no array 'urls'
    get_urls(page)

    #imprime urls de diretórios
    print "\nUrls de diretorios: \n"
    print "\n".join(urls_path)

    #imprime ulrs de arquivos
    print "\nUrls de arquivos: \n"
    print "\n".join(urls_file)


def get_site(url):
    return str(url).replace("[", "").replace("]", "").replace("'", "")


def read_site(url):
    f = urllib.urlopen(url)
    return f.read()


def get_urls(page):
    ls_tag = str(page).split("<")
    for tag in ls_tag:
        ls_cb = tag.split("\"")
        for cb in ls_cb:
            if cb.startswith("http"):
                add_url(cb)


def add_url(url):
    #Verifica se é um diretório
    if url.endswith("/"):
        if not urls_path.__contains__(url):
            urls_path.append(url)
    #caso não seja um diretório, entende que é um arquivo
    else:
        if not urls_file.__contains__(url):
            urls_file.append(url)


if __name__ == "__main__":
    initialize()